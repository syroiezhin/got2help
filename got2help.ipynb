{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        __  ______ _       ________  __        _ \n",
    "       / / / / __ \\ |     / / __ \\ \\/ /  _    | |\n",
    "      / /_/ / / / / | /| / / / / /\\  /  (_)   / /\n",
    "     / __  / /_/ /| |/ |/ / /_/ / / /  _     / / \n",
    "    /_/ /_/\\____/ |__/|__/_____/ /_/  (_)  _/_/  \n",
    "                                          /_/    \n",
    "                                                      \n",
    "               5168 7450 1701 5535     \n",
    "\n",
    "                 author = Valerij Syroiezhin\n",
    "               telegram = @NEU3RON\n",
    "                  email = v.syroiezhin@gmail.com\n",
    "                    url = https://github.com/syroiezhin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è The code below needs to be run in a file with a \".py\" extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úçüèªüëÇüèª I want to use a simple option to convert voice to text, and there is no desire to look for other options, since the user will not notice a significant difference, and in any case, I will have to work hard with installing pyaudio! There is no way to avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_recognition import Microphone, Recognizer\n",
    "\n",
    "def speech(source):\n",
    "    sr = Recognizer()\n",
    "    sr.pause_threshold = 0.5\n",
    "    sr.adjust_for_ambient_noise(source=source, duration=0.5)\n",
    "    audio_data = sr.listen(source=source)\n",
    "    with open(f\"audio.wav\", \"wb\") as file: file.write(audio_data.get_wav_data()) # wav, raw, aiff, flac\n",
    "    return sr.recognize_google(audio_data=audio_data, language='ru-RU').lower()\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    with Microphone() as source: print( speech(source) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ü§ñ There are different options for translating text into voice, but I need to write a program on Mac OS, and use it on Windows!\n",
    "##### The first option, of course, is from Google, but there are difficulties with choosing a language, since there is no choice...\n",
    "##### I don't have much time to reinvent my wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "from os import path, system\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        tts = gTTS('–∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞, –¥—Ä—É–≥', lang='ru')\n",
    "        if path.exists('gtts_0.mp3') == False: tts.save('gtts_0.mp3')\n",
    "        else: print(\"True\")\n",
    "    except: pass\n",
    "    finally: system('afplay gtts_0.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üêµ The second option is more interesting, there are more voice acting options, but the voice of the robot is felt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        tts = pyttsx3.init()\n",
    "        tts.setProperty('voice', tts.getProperty('voices')[49].id) # Russian : 19,29,49\n",
    "        tts.say(\"–∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞, –¥—Ä—É–≥\")\n",
    "    except: pass\n",
    "    finally: tts.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üëΩ It turned out to be the coolest option with voice acting. He is so amazing. \n",
    "#### Although \"there is no limit to perfection.\" \n",
    "#### Of course, there is room for improvement, \n",
    "#### but against the background of previous options, this one is promising.\n",
    "#### I really liked the latest version of the library v3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sounddevice import play, wait\n",
    "from torch import device, hub\n",
    "from time import sleep\n",
    "\n",
    "def say(speech):\n",
    "\n",
    "    sr = 48000\n",
    "    spd = int(sr * 4/5)  # in connection with the fast speech, Eugene decided to slow down his talk\n",
    "    language = 'ru'      # Please study the library in the documentation :\n",
    "    model_id = 'v3_1_ru' # github.com/snakers4/silero-models\n",
    "    speaker = 'eugene'   # select character voice : aidar,eugene,random,baya,kseniya,xenia\n",
    "\n",
    "    model, _ = hub.load( repo_or_dir = 'snakers4/silero-models' , model = 'silero_tts' , language = language , speaker = model_id )\n",
    "    model.to(device('cpu'))\n",
    "    audio = model.apply_tts( text = speech , speaker = speaker , sample_rate = sr )\n",
    "    \n",
    "    play( audio , spd )\n",
    "    wait()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    speech = ' –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç —Å–æ–ª–Ω—Ü–µ; –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç –Ω–µ–±–æ; –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç –º–∞–º–∞; –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥—É —è '\n",
    "    say(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è Before you start applying it on your macos - study the documentation and my manual on the project page!\n",
    "# üìù https://github.com/syroiezhin/got2help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î A friend asked to make a function that from OGG format will receive a text version of the audio record üî•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_recognition import Recognizer, AudioFile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def ogg2wav(NAME): AudioSegment.from_ogg(f'{NAME}.ogg').export(f\"{NAME}.wav\", format=\"wav\")\n",
    "\n",
    "def content(source, Recognizer): return Recognizer.recognize_google(Recognizer.record(source), language='ru-RU')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    NAME = 'audio'\n",
    "    ogg2wav(NAME)\n",
    "    with AudioFile(f\"{NAME}.wav\") as source: print( content( source, Recognizer() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üëπ I'm creating a **repeated flight** that saves a recorded file and a file with the voice of the character Evgeniy from the SoundDevice library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_recognition import Recognizer, Microphone, AudioFile\n",
    "from sounddevice import playrec, wait\n",
    "from torch import device, hub\n",
    "from soundfile import write\n",
    "\n",
    "def audio2text(recognizer, source): return recognizer.recognize_google( audio_data = recognizer.record(source) , language='ru-RU' )\n",
    "\n",
    "def hear(recognizer, source, NAME):\n",
    "    recognizer.pause_threshold = 1\n",
    "    recognizer.adjust_for_ambient_noise( source = source , duration = 0.5 )\n",
    "    audio_data = recognizer.listen(source)\n",
    "    with open(f\"{NAME}.wav\", \"wb\") as file: file.write(audio_data.get_wav_data()) # raw, aiff, flac\n",
    "    return recognizer.recognize_google( audio_data = audio_data , language = 'ru-RU' ).lower()\n",
    "\n",
    "def say(speech, NAME):\n",
    "    sr = 48000\n",
    "    spd = int(sr * 4/5)\n",
    "    language = 'ru'      # Please study the library in the documentation :\n",
    "    model_id = 'v3_1_ru' # github.com/snakers4/silero-models\n",
    "    speaker = 'eugene'   # select character voice : aidar,eugene,random,baya,kseniya,xenia\n",
    "    model, _ = hub.load( repo_or_dir = 'snakers4/silero-models' , model = 'silero_tts' , language = language , speaker = model_id )\n",
    "    model.to(device('cpu'))\n",
    "    audio = model.apply_tts( text = speech , speaker = speaker , sample_rate = sr )\n",
    "    print(audio)\n",
    "    rec = playrec( audio , spd , channels = 1 , blocking = True )\n",
    "    wait()\n",
    "    write( f'{NAME}.ogg', rec , spd )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    NAME = 'audio'\n",
    "    recognizer = Recognizer()\n",
    "    with Microphone() as source: heard = hear(recognizer, source, NAME)\n",
    "    with AudioFile(f\"{NAME}.wav\") as source: content = audio2text(recognizer, source)\n",
    "    print(content)\n",
    "    say(heard, NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "'''\n",
    "LDFLAGS=\"-L$(brew --prefix portaudio)/lib\" CFLAGS=\"-I$(brew --prefix portaudio)/include\" pip install pyaudio\n",
    "conda install -c conda-forge speechrecognition\n",
    "conda install -c pytorch torchaudio\n",
    "conda install -c pytorch pytorch\n",
    "pip install omegaconf\n",
    "'''\n",
    "\n",
    "from speech_recognition import Recognizer, Microphone\n",
    "from torch import device, hub\n",
    "from torchaudio import save\n",
    "from os.path import isfile\n",
    "from os import system\n",
    "\n",
    "def say(NAME,speech): start() if speech == None else [ save(f'{NAME}.mp3', speech.unsqueeze(0) , sample_rate = 48000 ), system(f'afplay {NAME}.mp3') ]\n",
    "\n",
    "def brain(voice,speech):\n",
    "    model, _ = hub.load( repo_or_dir='snakers4/silero-models', model='silero_tts', language='ru', speaker='v3_1_ru' ) ; model.to(device('cpu'))\n",
    "    if isfile(voice): return model.apply_tts( voice_path=voice, ssml_text=speech, speaker='random', sample_rate=48000, put_accent=True, put_yo=True )\n",
    "    else: model.apply_tts( ssml_text=speech, speaker='random', sample_rate=48000, put_accent=True, put_yo=True ) ; model.save_random_voice(voice) ; return None\n",
    "\n",
    "def hear(): \n",
    "    with Microphone() as source: \n",
    "        recognizer = Recognizer()\n",
    "        recognizer.pause_threshold = 1\n",
    "        recognizer.adjust_for_ambient_noise( source=source, duration=0.5 )\n",
    "        return recognizer.recognize_google( audio_data=recognizer.listen(source), language='ru-RU' ).lower()\n",
    "\n",
    "def start(): \n",
    "    heard = \"\"\"<speak><p>\n",
    "                  <p>–Å–ª–∫–∞, –ø—á—ë–ª–∫–∞ –∏ –±–∞—Ä+–∞–Ω</p>\n",
    "                  –ö–æ–≥–¥–∞ —è –ø—Ä–æ—Å—ã–ø–∞—é—Å—å, <prosody rate=\"x-slow\">—è –≥–æ–≤–æ—Ä—é –¥–æ–≤–æ–ª—å–Ω–æ –º–µ–¥–ª–µ–Ω–Ω–æ</prosody>.\n",
    "                  –ü–æ—Ç–æ–º —è –Ω–∞—á–∏–Ω–∞—é –≥–æ–≤–æ—Ä–∏—Ç—å —Å–≤–æ–∏–º –æ–±—ã—á–Ω—ã–º –≥–æ–ª–æ—Å–æ–º,\n",
    "                  <prosody pitch=\"x-high\"> –∞ –º–æ–≥—É –≥–æ–≤–æ—Ä–∏—Ç—å —Ç–æ–Ω–æ–º –≤—ã—à–µ </prosody>,\n",
    "                  –∏–ª–∏ <prosody pitch=\"x-low\">–Ω–∞–æ–±–æ—Ä–æ—Ç, –Ω–∏–∂–µ</prosody>.\n",
    "                  –ü–æ—Ç–æ–º, –µ—Å–ª–∏ –ø–æ–≤–µ–∑–µ—Ç ‚Äì <prosody rate=\"fast\">—è –º–æ–≥—É –≥–æ–≤–æ—Ä–∏—Ç—å –∏ –¥–æ–≤–æ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–æ.</prosody>\n",
    "                  –ê –µ—â–µ —è —É–º–µ—é –¥–µ–ª–∞—Ç—å –ø–∞—É–∑—ã –ª—é–±–æ–π –¥–ª–∏–Ω—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä –¥–≤–µ —Å–µ–∫—É–Ω–¥—ã <break time=\"2000ms\"/>.\n",
    "                  <p>–¢–∞–∫–∂–µ —è —É–º–µ—é –¥–µ–ª–∞—Ç—å –ø–∞—É–∑—ã –º–µ–∂–¥—É –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º–∏.</p>\n",
    "                  <p><s>–ò —Ç–∞–∫–∂–µ —è —É–º–µ—é –¥–µ–ª–∞—Ç—å –ø–∞—É–∑—ã –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏, –∫–∞–∫ —Å–µ–π—á–∞—Å</s><s>–£—Å–ª—ã—à–∞–ª–∏?</s></p>\n",
    "               </p></speak>\"\"\"\n",
    "\n",
    "    # heard = f\"\"\"<speak>{hear()}</speak>\"\"\" # Microphone\n",
    "    speech = brain('voice.pt',heard)\n",
    "    say('audio',speech)\n",
    "\n",
    "if __name__ == \"__main__\": start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f23284fad75d58360d212629b595dfe6fd02dbd8325e77387b1e5cbaad4e030"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
