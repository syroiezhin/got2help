{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        __  ______ _       ________  __        _ \n",
    "       / / / / __ \\ |     / / __ \\ \\/ /  _    | |\n",
    "      / /_/ / / / / | /| / / / / /\\  /  (_)   / /\n",
    "     / __  / /_/ /| |/ |/ / /_/ / / /  _     / / \n",
    "    /_/ /_/\\____/ |__/|__/_____/ /_/  (_)  _/_/  \n",
    "                                          /_/    \n",
    "                                                      \n",
    "               5168 7450 1701 5535     \n",
    "\n",
    "                 author = Valerij Syroiezhin\n",
    "               telegram = @NEU3RON\n",
    "                  email = v.syroiezhin@gmail.com\n",
    "                    url = https://github.com/syroiezhin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è The code below needs to be run in a file with a \".py\" extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úçüèªüëÇüèª I want to use a simple option to convert voice to text, and there is no desire to look for other options, since the user will not notice a significant difference, and in any case, I will have to work hard with installing pyaudio! There is no way to avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_recognition import Microphone, Recognizer\n",
    "\n",
    "def speech(source):\n",
    "    sr = Recognizer()\n",
    "    sr.pause_threshold = 0.5\n",
    "    sr.adjust_for_ambient_noise(source=source, duration=0.5)\n",
    "    audio_data = sr.listen(source=source)\n",
    "    with open(f\"audio.wav\", \"wb\") as file: file.write(audio_data.get_wav_data()) # wav, raw, aiff, flac\n",
    "    return sr.recognize_google(audio_data=audio_data, language='ru-RU').lower()\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    with Microphone() as source: print( speech(source) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ü§ñ There are different options for translating text into voice, but I need to write a program on Mac OS, and use it on Windows!\n",
    "##### The first option, of course, is from Google, but there are difficulties with choosing a language, since there is no choice...\n",
    "##### I don't have much time to reinvent my wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "from os import path, system\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        tts = gTTS('–∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞, –¥—Ä—É–≥', lang='ru')\n",
    "        if path.exists('gtts_0.mp3') == False: tts.save('gtts_0.mp3')\n",
    "        else: print(\"True\")\n",
    "    except: pass\n",
    "    finally: system('afplay gtts_0.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üêµ The second option is more interesting, there are more voice acting options, but the voice of the robot is felt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        tts = pyttsx3.init()\n",
    "        tts.setProperty('voice', tts.getProperty('voices')[49].id) # Russian : 19,29,49\n",
    "        tts.say(\"–∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞, –¥—Ä—É–≥\")\n",
    "    except: pass\n",
    "    finally: tts.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üëΩ It turned out to be the coolest option with voice acting. He is so amazing. \n",
    "#### Although \"there is no limit to perfection.\" \n",
    "#### Of course, there is room for improvement, \n",
    "#### but against the background of previous options, this one is promising.\n",
    "#### I really liked the latest version of the library v3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sounddevice import play, wait\n",
    "from torch import device, hub\n",
    "from time import sleep\n",
    "\n",
    "def say(speech):\n",
    "\n",
    "    sr = 48000\n",
    "    spd = int(sr * 4/5)  # in connection with the fast speech, Eugene decided to slow down his talk\n",
    "    language = 'ru'      # Please study the library in the documentation :\n",
    "    model_id = 'v3_1_ru' # github.com/snakers4/silero-models\n",
    "    speaker = 'eugene'   # select character voice : aidar,eugene,random,baya,kseniya,xenia\n",
    "\n",
    "    model, _ = hub.load( repo_or_dir = 'snakers4/silero-models' , model = 'silero_tts' , language = language , speaker = model_id )\n",
    "    model.to(device('cpu'))\n",
    "    audio = model.apply_tts( text = speech , speaker = speaker , sample_rate = sr )\n",
    "    \n",
    "    play( audio , spd )\n",
    "    wait()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    speech = ' –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç —Å–æ–ª–Ω—Ü–µ; –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç –Ω–µ–±–æ; –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç –º–∞–º–∞; –ü—É—Å—Ç—å –≤—Å–µ–≥–¥–∞ –±—É–¥—É —è '\n",
    "    say(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è Before you start applying it on your macos - study the documentation and my manual on the project page!\n",
    "# üìù https://github.com/syroiezhin/got2help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î A friend asked to make a function that from OGG format will receive a text version of the audio record üî•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_recognition import Recognizer, AudioFile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def ogg2wav(NAME): AudioSegment.from_ogg(f'{NAME}.ogg').export(f\"{NAME}.wav\", format=\"wav\")\n",
    "\n",
    "def content(source, Recognizer): return Recognizer.recognize_google(Recognizer.record(source), language='ru-RU')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    NAME = 'audio'\n",
    "    ogg2wav(NAME)\n",
    "    with AudioFile(f\"{NAME}.wav\") as source: print( content( source, Recognizer() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üëπ I'm creating a **repeated flight** that saves a recorded file and a file with the voice of the character Evgeniy from the SoundDevice library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_recognition import Recognizer, Microphone, AudioFile\n",
    "from sounddevice import playrec, wait\n",
    "from torch import device, hub\n",
    "from soundfile import write\n",
    "\n",
    "def audio2text(recognizer, source): return recognizer.recognize_google( audio_data = recognizer.record(source) , language='ru-RU' )\n",
    "\n",
    "def hear(recognizer, source, NAME):\n",
    "    recognizer.pause_threshold = 1\n",
    "    recognizer.adjust_for_ambient_noise( source = source , duration = 0.5 )\n",
    "    audio_data = recognizer.listen(source)\n",
    "    with open(f\"{NAME}.wav\", \"wb\") as file: file.write(audio_data.get_wav_data()) # raw, aiff, flac\n",
    "    return recognizer.recognize_google( audio_data = audio_data , language = 'ru-RU' ).lower()\n",
    "\n",
    "def say(speech, NAME):\n",
    "    sr = 48000\n",
    "    spd = int(sr * 4/5)\n",
    "    language = 'ru'      # Please study the library in the documentation :\n",
    "    model_id = 'v3_1_ru' # github.com/snakers4/silero-models\n",
    "    speaker = 'eugene'   # select character voice : aidar,eugene,random,baya,kseniya,xenia\n",
    "    model, _ = hub.load( repo_or_dir = 'snakers4/silero-models' , model = 'silero_tts' , language = language , speaker = model_id )\n",
    "    model.to(device('cpu'))\n",
    "    audio = model.apply_tts( text = speech , speaker = speaker , sample_rate = sr )\n",
    "    rec = playrec( audio , spd , channels = 1 , blocking = True )\n",
    "    wait()\n",
    "    write( f'{NAME}.ogg', rec , spd )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    NAME = 'audio'\n",
    "    recognizer = Recognizer()\n",
    "    with Microphone() as source: heard = hear(recognizer, source, NAME)\n",
    "    with AudioFile(f\"{NAME}.wav\") as source: content = audio2text(recognizer, source)\n",
    "    print(content)\n",
    "    say(heard, NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f23284fad75d58360d212629b595dfe6fd02dbd8325e77387b1e5cbaad4e030"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
