{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        __  ______ _       ________  __        _ \n",
    "       / / / / __ \\ |     / / __ \\ \\/ /  _    | |\n",
    "      / /_/ / / / / | /| / / / / /\\  /  (_)   / /\n",
    "     / __  / /_/ /| |/ |/ / /_/ / / /  _     / / \n",
    "    /_/ /_/\\____/ |__/|__/_____/ /_/  (_)  _/_/  \n",
    "                                          /_/    \n",
    "                                                      \n",
    "               5168 7450 1701 5535     \n",
    "\n",
    "                 author = Valerij Syroiezhin\n",
    "               telegram = @NEU3RON\n",
    "                  email = v.syroiezhin@gmail.com\n",
    "                    url = https://github.com/syroiezhin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš ï¸ The code below needs to be run in a file with a \".py\" extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### âœðŸ»ðŸ‘‚ðŸ» I want to use a simple option to convert voice to text, and there is no desire to look for other options, since the user will not notice a significant difference, and in any case, I will have to work hard with installing pyaudio! There is no way to avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition\n",
    "\n",
    "sr = speech_recognition.Recognizer()\n",
    "sr.pause_threshold = 0.5\n",
    "\n",
    "with speech_recognition.Microphone() as mic:\n",
    "    sr.adjust_for_ambient_noise(source=mic, duration=0.5)\n",
    "    audio = sr.listen(source=mic)\n",
    "    query = sr.recognize_google(audio_data=audio, language='ru-RU').lower()\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤– There are different options for translating text into voice, but I need to write a program on Mac OS, and use it on Windows!\n",
    "##### The first option, of course, is from Google, but there are difficulties with choosing a language, since there is no choice...\n",
    "##### I don't have much time to reinvent my wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "from os import path, system\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        tts = gTTS('ÐºÐ°Ðº Ñ‚Ð²Ð¾Ð¸ Ð´ÐµÐ»Ð°, Ð´Ñ€ÑƒÐ³', lang='ru')\n",
    "        if path.exists('gtts_0.mp3') == False: tts.save('gtts_0.mp3')\n",
    "        else: print(\"True\")\n",
    "    except: pass\n",
    "    finally: system('afplay gtts_0.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ðŸµ The second option is more interesting, there are more voice acting options, but the voice of the robot is felt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        tts = pyttsx3.init()\n",
    "        tts.setProperty('voice', tts.getProperty('voices')[49].id) # Russian : 19,29,49\n",
    "        tts.say(\"ÐºÐ°Ðº Ñ‚Ð²Ð¾Ð¸ Ð´ÐµÐ»Ð°, Ð´Ñ€ÑƒÐ³\")\n",
    "    except: pass\n",
    "    finally: tts.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ‘½ It turned out to be the coolest option with voice acting. He is so amazing. \n",
    "#### Although \"there is no limit to perfection.\" \n",
    "#### Of course, there is room for improvement, \n",
    "#### but against the background of previous options, this one is promising.\n",
    "#### I really liked the latest version of the library v3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sounddevice import play, stop\n",
    "from torch import device, hub\n",
    "from time import sleep\n",
    "\n",
    "def ceil(num, decimal): return int( num*10**decimal + 0.5 if num > 0 else 0.5 - num*10**decimal )/10**decimal\n",
    "\n",
    "language = 'ru'      # Please study the library in the documentation :\n",
    "model_id = 'v3_1_ru' # github.com/snakers4/silero-models\n",
    "frequency = 48000\n",
    "\n",
    "speed = 0.8        # in connection with the fast speech, Eugene decided to slow down his talk\n",
    "                   # norm = 1.0\n",
    "\n",
    "speaker = 'eugene' # select character voice :\n",
    "''' \n",
    "                         Russian: { \n",
    "                             Male:   { \n",
    "                                 aidar, \n",
    "                                 eugene, \n",
    "                                 random \n",
    "                                 }, \n",
    "                             Female: { \n",
    "                                 baya, \n",
    "                                 kseniya, \n",
    "                                 xenia\n",
    "                                 } \n",
    "                             }\n",
    "'''\n",
    "\n",
    "speech = ' ÐŸÑƒÑÑ‚ÑŒ Ð²ÑÐµÐ³Ð´Ð° Ð±ÑƒÐ´ÐµÑ‚ ÑÐ¾Ð»Ð½Ñ†Ðµ; ÐŸÑƒÑÑ‚ÑŒ Ð²ÑÐµÐ³Ð´Ð° Ð±ÑƒÐ´ÐµÑ‚ Ð½ÐµÐ±Ð¾; ÐŸÑƒÑÑ‚ÑŒ Ð²ÑÐµÐ³Ð´Ð° Ð±ÑƒÐ´ÐµÑ‚ Ð¼Ð°Ð¼Ð°; ÐŸÑƒÑÑ‚ÑŒ Ð²ÑÐµÐ³Ð´Ð° Ð±ÑƒÐ´Ñƒ Ñ '\n",
    "\n",
    "model, _ = hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=model_id)\n",
    "model.to(device('cpu'))\n",
    "audio = model.apply_tts(text=speech, speaker=speaker, sample_rate=frequency)\n",
    "\n",
    "play( audio , frequency*speed )\n",
    "sleep( ceil( (len(audio)/frequency)/speed , 2 ) )\n",
    "stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### âš ï¸ Before you start applying it on your macos - study the documentation and my manual on the project page!\n",
    "# ðŸ“ https://github.com/syroiezhin/got2help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘¹ Apply the collected knowledge in a pile. We donâ€™t have to think for a long time, we create a **repeated flight**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_recognition import Recognizer, Microphone\n",
    "from sounddevice import play, stop\n",
    "from torch import device, hub\n",
    "from time import sleep\n",
    "\n",
    "def ceil(num, decimal): return int( num*10**decimal + 0.5 if num > 0 else 0.5 - num*10**decimal )/10**decimal\n",
    "\n",
    "def hear():\n",
    "    sr = Recognizer()\n",
    "    sr.pause_threshold = 1\n",
    "    \n",
    "    with Microphone() as mic: \n",
    "        sr.adjust_for_ambient_noise(source=mic, duration=0.5)\n",
    "        return sr.recognize_google(audio_data=sr.listen(source=mic), language='ru-RU').lower()\n",
    "\n",
    "def say(speech):\n",
    "    frequency = 48000\n",
    "    language = 'ru'\n",
    "    model_id = 'v3_1_ru'\n",
    "    speed = 0.8          # norm = 1.0\n",
    "    speaker = 'eugene'   # aidar,eugene,random,baya,kseniya,xenia\n",
    "    model, _ = hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=model_id)\n",
    "    model.to(device('cpu'))\n",
    "    audio = model.apply_tts(text=speech, speaker=speaker, sample_rate=frequency)\n",
    "    play( audio , frequency*speed )\n",
    "    sleep( ceil( (len(audio)/frequency)/speed , 2 ) )\n",
    "    stop()\n",
    "    return speech\n",
    "\n",
    "if __name__ == \"__main__\": print(say(hear()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¤” A friend asked to make a function that from OGG format will receive a text version of the audio record ðŸ”¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_recognition import Recognizer, AudioFile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def ogg2wav(NAME): AudioSegment.from_ogg(f'{NAME}.ogg').export(f\"{NAME}.wav\", format=\"wav\")\n",
    "\n",
    "def content(source, Recognizer): return Recognizer.recognize_google(Recognizer.record(source), language='ru-RU')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    NAME = 'audio'\n",
    "    ogg2wav(NAME)\n",
    "    with AudioFile(f\"{NAME}.wav\") as source: print( content( source, Recognizer() ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f23284fad75d58360d212629b595dfe6fd02dbd8325e77387b1e5cbaad4e030"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
